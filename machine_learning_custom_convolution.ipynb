{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "277/277 - 1s - loss: 6.9626 - mse: 0.1274\n",
      "Epoch 2/150\n",
      "277/277 - 1s - loss: 0.4434 - mse: 0.0942\n",
      "Epoch 3/150\n",
      "277/277 - 1s - loss: 0.4373 - mse: 0.0941\n",
      "Epoch 4/150\n",
      "277/277 - 1s - loss: 0.4366 - mse: 0.0941\n",
      "Epoch 5/150\n",
      "277/277 - 1s - loss: 0.4356 - mse: 0.0941\n",
      "Epoch 6/150\n",
      "277/277 - 1s - loss: 0.4359 - mse: 0.0941\n",
      "Epoch 7/150\n",
      "277/277 - 1s - loss: 0.4365 - mse: 0.0941\n",
      "Epoch 8/150\n",
      "277/277 - 1s - loss: 0.4359 - mse: 0.0941\n",
      "Epoch 9/150\n",
      "277/277 - 1s - loss: 0.4360 - mse: 0.0941\n",
      "Epoch 10/150\n",
      "277/277 - 1s - loss: 0.4360 - mse: 0.0941\n",
      "Epoch 11/150\n",
      "277/277 - 1s - loss: 0.4371 - mse: 0.0941\n",
      "Epoch 12/150\n",
      "277/277 - 1s - loss: 0.4362 - mse: 0.0941\n",
      "Epoch 13/150\n",
      "277/277 - 1s - loss: 0.4366 - mse: 0.0941\n",
      "Epoch 14/150\n",
      "277/277 - 1s - loss: 0.4367 - mse: 0.0942\n",
      "Epoch 15/150\n",
      "277/277 - 1s - loss: 0.4365 - mse: 0.0941\n",
      "Epoch 16/150\n",
      "277/277 - 1s - loss: 0.4368 - mse: 0.0942\n",
      "Epoch 17/150\n",
      "277/277 - 1s - loss: 0.4377 - mse: 0.0942\n",
      "Epoch 18/150\n",
      "277/277 - 1s - loss: 0.4368 - mse: 0.0941\n",
      "Epoch 19/150\n",
      "277/277 - 1s - loss: 0.4372 - mse: 0.0941\n",
      "Epoch 20/150\n",
      "277/277 - 1s - loss: 0.4375 - mse: 0.0941\n",
      "Epoch 21/150\n",
      "277/277 - 1s - loss: 0.4377 - mse: 0.0941\n",
      "Epoch 22/150\n",
      "277/277 - 1s - loss: 0.4380 - mse: 0.0941\n",
      "Epoch 23/150\n",
      "277/277 - 1s - loss: 0.4382 - mse: 0.0941\n",
      "Epoch 24/150\n",
      "277/277 - 1s - loss: 0.4387 - mse: 0.0941\n",
      "Epoch 25/150\n",
      "277/277 - 1s - loss: 0.4390 - mse: 0.0940\n",
      "Epoch 26/150\n",
      "277/277 - 1s - loss: 0.4396 - mse: 0.0939\n",
      "Epoch 27/150\n",
      "277/277 - 1s - loss: 0.4412 - mse: 0.0934\n",
      "Epoch 28/150\n",
      "277/277 - 1s - loss: 0.4305 - mse: 0.0856\n",
      "Epoch 29/150\n",
      "277/277 - 1s - loss: 0.4098 - mse: 0.0752\n",
      "Epoch 30/150\n",
      "277/277 - 1s - loss: 0.4057 - mse: 0.0737\n",
      "Epoch 31/150\n",
      "277/277 - 2s - loss: 0.4008 - mse: 0.0729\n",
      "Epoch 32/150\n",
      "277/277 - 1s - loss: 0.4004 - mse: 0.0727\n",
      "Epoch 33/150\n",
      "277/277 - 1s - loss: 0.3933 - mse: 0.0715\n",
      "Epoch 34/150\n",
      "277/277 - 1s - loss: 0.3925 - mse: 0.0710\n",
      "Epoch 35/150\n",
      "277/277 - 1s - loss: 0.3903 - mse: 0.0705\n",
      "Epoch 36/150\n",
      "277/277 - 1s - loss: 0.3889 - mse: 0.0704\n",
      "Epoch 37/150\n",
      "277/277 - 1s - loss: 0.3862 - mse: 0.0699\n",
      "Epoch 38/150\n",
      "277/277 - 1s - loss: 0.3857 - mse: 0.0698\n",
      "Epoch 39/150\n",
      "277/277 - 1s - loss: 0.3846 - mse: 0.0695\n",
      "Epoch 40/150\n",
      "277/277 - 1s - loss: 0.3836 - mse: 0.0693\n",
      "Epoch 41/150\n",
      "277/277 - 1s - loss: 0.3836 - mse: 0.0692\n",
      "Epoch 42/150\n",
      "277/277 - 2s - loss: 0.3940 - mse: 0.0698\n",
      "Epoch 43/150\n",
      "277/277 - 2s - loss: 0.3810 - mse: 0.0687\n",
      "Epoch 44/150\n",
      "277/277 - 1s - loss: 0.3798 - mse: 0.0685\n",
      "Epoch 45/150\n",
      "277/277 - 2s - loss: 0.3807 - mse: 0.0684\n",
      "Epoch 46/150\n",
      "277/277 - 1s - loss: 0.3801 - mse: 0.0683\n",
      "Epoch 47/150\n",
      "277/277 - 1s - loss: 0.3807 - mse: 0.0682\n",
      "Epoch 48/150\n",
      "277/277 - 1s - loss: 0.3793 - mse: 0.0680\n",
      "Epoch 49/150\n",
      "277/277 - 1s - loss: 0.3790 - mse: 0.0679\n",
      "Epoch 50/150\n",
      "277/277 - 1s - loss: 0.3781 - mse: 0.0677\n",
      "Epoch 51/150\n",
      "277/277 - 1s - loss: 0.3790 - mse: 0.0677\n",
      "Epoch 52/150\n",
      "277/277 - 1s - loss: 0.3780 - mse: 0.0675\n",
      "Epoch 53/150\n",
      "277/277 - 1s - loss: 0.3784 - mse: 0.0673\n",
      "Epoch 54/150\n",
      "277/277 - 1s - loss: 0.3786 - mse: 0.0673\n",
      "Epoch 55/150\n",
      "277/277 - 1s - loss: 0.3820 - mse: 0.0675\n",
      "Epoch 56/150\n",
      "277/277 - 1s - loss: 0.3799 - mse: 0.0672\n",
      "Epoch 57/150\n",
      "277/277 - 1s - loss: 0.3767 - mse: 0.0670\n",
      "Epoch 58/150\n",
      "277/277 - 1s - loss: 0.3797 - mse: 0.0670\n",
      "Epoch 59/150\n",
      "277/277 - 1s - loss: 0.3751 - mse: 0.0666\n",
      "Epoch 60/150\n",
      "277/277 - 1s - loss: 0.3753 - mse: 0.0665\n",
      "Epoch 61/150\n",
      "277/277 - 1s - loss: 0.3754 - mse: 0.0664\n",
      "Epoch 62/150\n",
      "277/277 - 1s - loss: 0.3749 - mse: 0.0662\n",
      "Epoch 63/150\n",
      "277/277 - 1s - loss: 0.3777 - mse: 0.0663\n",
      "Epoch 64/150\n",
      "277/277 - 1s - loss: 0.3742 - mse: 0.0660\n",
      "Epoch 65/150\n",
      "277/277 - 1s - loss: 0.3799 - mse: 0.0666\n",
      "Epoch 66/150\n",
      "277/277 - 1s - loss: 0.3746 - mse: 0.0659\n",
      "Epoch 67/150\n",
      "277/277 - 1s - loss: 0.3725 - mse: 0.0657\n",
      "Epoch 68/150\n",
      "277/277 - 1s - loss: 0.3722 - mse: 0.0656\n",
      "Epoch 69/150\n",
      "277/277 - 1s - loss: 0.3734 - mse: 0.0655\n",
      "Epoch 70/150\n",
      "277/277 - 1s - loss: 0.3721 - mse: 0.0654\n",
      "Epoch 71/150\n",
      "277/277 - 1s - loss: 0.3726 - mse: 0.0654\n",
      "Epoch 72/150\n",
      "277/277 - 1s - loss: 0.3715 - mse: 0.0652\n",
      "Epoch 73/150\n",
      "277/277 - 1s - loss: 0.3718 - mse: 0.0652\n",
      "Epoch 74/150\n",
      "277/277 - 1s - loss: 0.3770 - mse: 0.0655\n",
      "Epoch 75/150\n",
      "277/277 - 1s - loss: 0.3731 - mse: 0.0652\n",
      "Epoch 76/150\n",
      "277/277 - 1s - loss: 0.3733 - mse: 0.0652\n",
      "Epoch 77/150\n",
      "277/277 - 1s - loss: 0.3702 - mse: 0.0649\n",
      "Epoch 78/150\n",
      "277/277 - 1s - loss: 0.3705 - mse: 0.0650\n",
      "Epoch 79/150\n",
      "277/277 - 1s - loss: 0.3695 - mse: 0.0648\n",
      "Epoch 80/150\n",
      "277/277 - 1s - loss: 0.3739 - mse: 0.0651\n",
      "Epoch 81/150\n",
      "277/277 - 1s - loss: 0.3712 - mse: 0.0648\n",
      "Epoch 82/150\n",
      "277/277 - 1s - loss: 0.3693 - mse: 0.0647\n",
      "Epoch 83/150\n",
      "277/277 - 1s - loss: 0.3695 - mse: 0.0647\n",
      "Epoch 84/150\n",
      "277/277 - 1s - loss: 0.3701 - mse: 0.0647\n",
      "Epoch 85/150\n",
      "277/277 - 1s - loss: 0.3673 - mse: 0.0644\n",
      "Epoch 86/150\n",
      "277/277 - 1s - loss: 0.3685 - mse: 0.0644\n",
      "Epoch 87/150\n",
      "277/277 - 1s - loss: 0.3689 - mse: 0.0645\n",
      "Epoch 88/150\n",
      "277/277 - 1s - loss: 0.3716 - mse: 0.0647\n",
      "Epoch 89/150\n",
      "277/277 - 1s - loss: 0.3701 - mse: 0.0645\n",
      "Epoch 90/150\n",
      "277/277 - 1s - loss: 0.3666 - mse: 0.0642\n",
      "Epoch 91/150\n",
      "277/277 - 1s - loss: 0.3673 - mse: 0.0642\n",
      "Epoch 92/150\n",
      "277/277 - 2s - loss: 0.3669 - mse: 0.0641\n",
      "Epoch 93/150\n",
      "277/277 - 2s - loss: 0.3751 - mse: 0.0646\n",
      "Epoch 94/150\n",
      "277/277 - 2s - loss: 0.3660 - mse: 0.0640\n",
      "Epoch 95/150\n",
      "277/277 - 2s - loss: 0.3665 - mse: 0.0640\n",
      "Epoch 96/150\n",
      "277/277 - 2s - loss: 0.3662 - mse: 0.0640\n",
      "Epoch 97/150\n",
      "277/277 - 2s - loss: 0.3660 - mse: 0.0639\n",
      "Epoch 98/150\n",
      "277/277 - 2s - loss: 0.3661 - mse: 0.0639\n",
      "Epoch 99/150\n",
      "277/277 - 2s - loss: 0.3895 - mse: 0.0662\n",
      "Epoch 100/150\n",
      "277/277 - 2s - loss: 0.3626 - mse: 0.0638\n",
      "Epoch 101/150\n",
      "277/277 - 2s - loss: 0.3638 - mse: 0.0637\n",
      "Epoch 102/150\n",
      "277/277 - 2s - loss: 0.3625 - mse: 0.0636\n",
      "Epoch 103/150\n",
      "277/277 - 2s - loss: 0.3633 - mse: 0.0636\n",
      "Epoch 104/150\n",
      "277/277 - 2s - loss: 0.3637 - mse: 0.0636\n",
      "Epoch 105/150\n",
      "277/277 - 2s - loss: 0.3688 - mse: 0.0641\n",
      "Epoch 106/150\n",
      "277/277 - 2s - loss: 0.3628 - mse: 0.0634\n",
      "Epoch 107/150\n",
      "277/277 - 2s - loss: 0.3646 - mse: 0.0636\n",
      "Epoch 108/150\n",
      "277/277 - 2s - loss: 0.3622 - mse: 0.0634\n",
      "Epoch 109/150\n",
      "277/277 - 2s - loss: 0.3652 - mse: 0.0634\n",
      "Epoch 110/150\n",
      "277/277 - 2s - loss: 0.3656 - mse: 0.0635\n",
      "Epoch 111/150\n",
      "277/277 - 2s - loss: 0.3736 - mse: 0.0649\n",
      "Epoch 112/150\n",
      "277/277 - 2s - loss: 0.3625 - mse: 0.0632\n",
      "Epoch 113/150\n",
      "277/277 - 2s - loss: 0.3644 - mse: 0.0633\n",
      "Epoch 114/150\n",
      "277/277 - 2s - loss: 0.3638 - mse: 0.0631\n",
      "Epoch 115/150\n",
      "277/277 - 2s - loss: 0.3614 - mse: 0.0630\n",
      "Epoch 116/150\n",
      "277/277 - 2s - loss: 0.3622 - mse: 0.0630\n",
      "Epoch 117/150\n",
      "277/277 - 2s - loss: 0.3629 - mse: 0.0630\n",
      "Epoch 118/150\n",
      "277/277 - 2s - loss: 0.3667 - mse: 0.0633\n",
      "Epoch 119/150\n",
      "277/277 - 2s - loss: 0.3648 - mse: 0.0633\n",
      "Epoch 120/150\n",
      "277/277 - 2s - loss: 0.3617 - mse: 0.0628\n",
      "Epoch 121/150\n",
      "277/277 - 2s - loss: 0.3614 - mse: 0.0627\n",
      "Epoch 122/150\n",
      "277/277 - 2s - loss: 0.3615 - mse: 0.0628\n",
      "Epoch 123/150\n",
      "277/277 - 2s - loss: 0.3607 - mse: 0.0626\n",
      "Epoch 124/150\n",
      "277/277 - 2s - loss: 0.3702 - mse: 0.0640\n",
      "Epoch 125/150\n",
      "277/277 - 2s - loss: 0.3598 - mse: 0.0626\n",
      "Epoch 126/150\n",
      "277/277 - 2s - loss: 0.3604 - mse: 0.0626\n",
      "Epoch 127/150\n",
      "277/277 - 2s - loss: 0.3627 - mse: 0.0628\n",
      "Epoch 128/150\n",
      "277/277 - 2s - loss: 0.3614 - mse: 0.0626\n",
      "Epoch 129/150\n",
      "277/277 - 2s - loss: 0.3607 - mse: 0.0625\n",
      "Epoch 130/150\n",
      "277/277 - 2s - loss: 0.3602 - mse: 0.0625\n",
      "Epoch 131/150\n",
      "277/277 - 2s - loss: 0.3601 - mse: 0.0625\n",
      "Epoch 132/150\n",
      "277/277 - 2s - loss: 0.3632 - mse: 0.0628\n",
      "Epoch 133/150\n",
      "277/277 - 2s - loss: 0.3609 - mse: 0.0625\n",
      "Epoch 134/150\n",
      "277/277 - 2s - loss: 0.3602 - mse: 0.0624\n",
      "Epoch 135/150\n",
      "277/277 - 2s - loss: 0.3605 - mse: 0.0624\n",
      "Epoch 136/150\n",
      "277/277 - 2s - loss: 0.3631 - mse: 0.0626\n",
      "Epoch 137/150\n",
      "277/277 - 2s - loss: 0.3594 - mse: 0.0622\n",
      "Epoch 138/150\n",
      "277/277 - 2s - loss: 0.3591 - mse: 0.0621\n",
      "Epoch 139/150\n",
      "277/277 - 2s - loss: 0.3636 - mse: 0.0625\n",
      "Epoch 140/150\n",
      "277/277 - 2s - loss: 0.3592 - mse: 0.0622\n",
      "Epoch 141/150\n",
      "277/277 - 2s - loss: 0.3596 - mse: 0.0622\n",
      "Epoch 142/150\n",
      "277/277 - 2s - loss: 0.3594 - mse: 0.0622\n",
      "Epoch 143/150\n",
      "277/277 - 2s - loss: 0.3602 - mse: 0.0623\n",
      "Epoch 144/150\n",
      "277/277 - 2s - loss: 0.3597 - mse: 0.0622\n",
      "Epoch 145/150\n",
      "277/277 - 2s - loss: 0.3596 - mse: 0.0621\n",
      "Epoch 146/150\n",
      "277/277 - 2s - loss: 0.3597 - mse: 0.0622\n",
      "Epoch 147/150\n",
      "277/277 - 2s - loss: 0.3598 - mse: 0.0621\n",
      "Epoch 148/150\n",
      "277/277 - 2s - loss: 0.3595 - mse: 0.0621\n",
      "Epoch 149/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277/277 - 2s - loss: 0.3594 - mse: 0.0621\n",
      "Epoch 150/150\n",
      "277/277 - 2s - loss: 0.3660 - mse: 0.0626\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Layer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "\n",
    "grade_to_ordinal_dummy_11_categories = {\n",
    "    'V4':[0,0,0,0,0,0,0,0,0,0],\n",
    "    'V5':[1,0,0,0,0,0,0,0,0,0],\n",
    "    'V6':[1,1,0,0,0,0,0,0,0,0],\n",
    "    'V7':[1,1,1,0,0,0,0,0,0,0],\n",
    "    'V8':[1,1,1,1,0,0,0,0,0,0],\n",
    "    'V9':[1,1,1,1,1,0,0,0,0,0],\n",
    "    'V10':[1,1,1,1,1,1,0,0,0,0],\n",
    "    'V11':[1,1,1,1,1,1,1,0,0,0],\n",
    "    'V12':[1,1,1,1,1,1,1,1,0,0],\n",
    "    'V13':[1,1,1,1,1,1,1,1,1,0],\n",
    "    'V14':[1,1,1,1,1,1,1,1,1,1]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "class Conv2D_centered(Layer):\n",
    "    # Custom convolution that acts non-trivially only when the center is nonzero (there is a hold there).\n",
    "    # As explained in the Powerpoint, the number of holds is upsampled to be equal (twelve holds total) in all problems.\n",
    "    # This way, the network can be expected to perform an averaging over the difficulty of the hold at the center, and\n",
    "    # the local environment around the holds in each problem. If the environment is, on average, crowded, the problem \n",
    "    # should be easier, while if it's not crowded it should be harder. A simple filter with a 1 at the center and negative\n",
    "    # isotropic values that fall off in magnitude with the distance would already accomplish a very rough measure of difficulty,\n",
    "    # assuming the rest of the network accomplishes a sort of average of these filtered values over all holds.\n",
    "    \n",
    "    def __init__(self, kernel_shape):\n",
    "        super(Conv2D_centered, self).__init__()\n",
    "        self.kernel_shape = kernel_shape\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=self.kernel_shape,\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.shape = input_shape\n",
    "        super(Conv2D_centered, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, matrix):\n",
    "        filtered = []\n",
    "        for m in range(self.kernel_shape[0]):\n",
    "            filtered.append(tf.reduce_sum(tf.reduce_sum(matrix*self.kernel[m], axis=-1), axis=-1))\n",
    "        filtered_concatenated =  tf.concat(filtered, axis=1)\n",
    "        return filtered_concatenated\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1]*self.kernel_shape[0])\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'kernel_shape': self.kernel_shape,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    \n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D_centered((50,13,13)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu', kernel_regularizer=regularizers.l1(0.02)))\n",
    "    model.add(Dense(10, activation='sigmoid'))\n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss= 'bce', metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "X_train = np.load('problems_train.npy')\n",
    "X_test = np.load('problems_test.npy')\n",
    "Y_train = np.load('grades_train.npy')\n",
    "Y_test = np.load('grades_test.npy')\n",
    "\n",
    "\n",
    "model = define_model()\n",
    "history = model.fit(X_train, Y_train, epochs=150, batch_size=64, verbose=2)\n",
    "\n",
    "binar = np.vectorize(lambda x: int(round(x)))\n",
    "Y_test_predicted = binar(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_1 scores over the 11 categories V4 - V14 are:\n",
      "[0.62002472 0.43494817 0.26822818 0.20308043 0.19180201 0.09312639\n",
      " 0.         0.         0.         0.         0.        ]\n",
      "Total accuracy is:\n",
      "0.39101717305150324\n",
      "AUC is:\n",
      "0.5824015140533447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-358f53c553eb>:16: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  precision = confusion[i,i]/np.sum(confusion[i,:])\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy\n",
    "\n",
    "confusion = np.zeros((11,11))\n",
    "labels = []\n",
    "for key,val in grade_to_ordinal_dummy_11_categories.items():\n",
    "    labels.append(val)\n",
    "\n",
    "for i in range(11):\n",
    "    for j in range(11):\n",
    "        for k in range(len(Y_test)):\n",
    "            if np.array_equal(Y_test[k],labels[i]) and np.array_equal(Y_test_predicted[k],labels[j]):\n",
    "                confusion[j,i] += 1\n",
    "f_1 = np.zeros(11)\n",
    "\n",
    "for i in range(11):\n",
    "    precision = confusion[i,i]/np.sum(confusion[i,:])\n",
    "    recall = confusion[i,i]/np.sum(confusion[:,i])\n",
    "    if recall + precision > 0:\n",
    "        f_1[i] = 2*precision*recall/(precision+recall)\n",
    "    else:\n",
    "        f_1[i] = 0\n",
    "        \n",
    "print(\"F_1 scores over the 11 categories V4 - V14 are:\")\n",
    "print(f_1)\n",
    "    \n",
    "    \n",
    "accuracy = 0\n",
    "for i in range(len(Y_test)):\n",
    "    if list(Y_test[i] - Y_test_predicted[i]) == [0,0,0,0,0,0,0,0,0,0]:\n",
    "        accuracy += 1/len(Y_test)\n",
    "print(\"Total accuracy is:\")\n",
    "print(accuracy)\n",
    "\n",
    "print(\"AUC is:\")\n",
    "print(float(tf.keras.metrics.AUC(multi_label = True)(Y_test, Y_test_predicted)))\n",
    "\n",
    "# Note:  if the machine learning is done with 6 categories (V4, V5, V6, V7, V8, V9+), the accuracy is about 42% and AUC 70%,\n",
    "# as presented in the Powerpoint.  However, I wanted to report the machine learning of 11 categories (V4 - V14), since that way \n",
    "# it can be compared to http://cs229.stanford.edu/proj2017/final-reports/5232206.pdf (where CNN accuracy was 34%).  \n",
    "# The accuracy I achieve is higher!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
